<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://alig146.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://alig146.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-09T18:37:26+00:00</updated><id>https://alig146.github.io/feed.xml</id><title type="html">Ali Garabaglu</title><subtitle>A simple, whitespace theme for academics. </subtitle><entry><title type="html">How to Consume Reality</title><link href="https://alig146.github.io/blog/2025/obervation/" rel="alternate" type="text/html" title="How to Consume Reality"/><published>2025-08-03T10:00:00+00:00</published><updated>2025-08-03T10:00:00+00:00</updated><id>https://alig146.github.io/blog/2025/obervation</id><content type="html" xml:base="https://alig146.github.io/blog/2025/obervation/"><![CDATA[<p>In both science and everyday experience, understanding the world begins with observation. We observe phenomena, analyze them, and construct models that help us explain, predict, and manipulate what we perceive. This process is central not only to human understanding but also increasingly to artificial intelligence , which now plays an active role in how we model reality.</p> <p>But what if we stepped back and re-examined the entire process of observation—not just as a passive act of seeing, but as an active, layered mechanism? And what if the traditional human-centered model of observation introduces limitations that AI could overcome?</p> <p>Let’s explore this idea by dissecting the observation pipeline into three fundamental stages: <strong>Reality → Observation → Model</strong>. Each stage plays a distinct role, and understanding their relationship can help us design AI systems that don’t just mimic human perception—but perhaps transcend it.</p> <p>Reality is the only stage that exists independently. It is the raw, unprocessed fabric of the universe, existing whether or not there is someone—or something—there to observe it. Rocks fall, stars explode, and particles interact, regardless of our awareness.</p> <p>This concept aligns with the scientific worldview: reality is objective and exists outside the observer. However, some interpretations in physics, such as the Anthropic Principle, suggest that our very presence as observers influences the kind of universe we can perceive or exist in. While intriguing, this philosophical twist doesn’t negate reality’s independence—it merely highlights that what we observe of it is constrained by our ability to exist within it.</p> <p>Observation sits between reality and the model. It is the middleman. It is the act of filtering raw reality through the senses, brain, and prior beliefs of the observer. This step is powerful, but it’s also perilous—because it is deeply subjective.</p> <p>When humans observe, we don’t take in reality in its raw form. Instead, we compress it. Our eyes detect only a narrow slice of the electromagnetic spectrum; our ears hear within a specific frequency range. Our brains process these signals through a complex web of prior experiences, language, and cultural context. What we “see” is never pure reality—it’s a filtered, interpreted, and often biased approximation.</p> <p>In a sense, the human brain acts like a compression algorithm, reducing the overwhelming detail of reality into a manageable model. This makes survival possible, but it also limits our understanding.</p> <p>Once observation has occurred, the mind builds a model, an internal representation of the external world. These models help us reason, predict, and make decisions. They’re not exact replicas of reality, but simplified versions tuned for efficiency, not accuracy.</p> <p>Models are everywhere. Newton’s laws model motion. Economic models predict markets. Even a child’s understanding that “fire is hot” is a model formed through limited experience.</p> <p>Artificial Intelligence, too, builds models. An AI trained to recognize cats doesn’t understand what a cat is, it compresses vast data into a pattern-recognition system that predicts “cat” when it sees certain features.</p> <p>In the traditional AI pipeline, humans serve as the “observer.” We decide what data to collect, what labels to assign, and how to preprocess it. We effectively insert ourselves between reality and the AI’s model, bringing all our human biases along for the ride.</p> <p>This raises a profound question: What if we could remove the human observer from the loop?</p> <p>Instead of feeding AI a human-preprocessed version of reality, what if we gave it raw interactions, measurements and allowed it to form its own model, untethered from our interpretations? We could perhaps allow the machine to take in all frequencies of light, acoustics and any other sensor we have at hand.</p> <p>Doing so would allow AI to develop intra-realities, internal representations of the world that aren’t inherited from humans, but emerge from the AI’s direct interaction with raw data. These intra-realities could differ from ours in fascinating, potentially more efficient ways.</p> <p>In some domains, like reinforcement learning, AI systems already do this to an extent—interacting with an environment and learning from the consequences. But even here, the environment is usually shaped by human design. The challenge—and opportunity—is to let AI connect more directly to reality, minimizing the biases of the middle step: human observation.</p> <p>The traditional chain—<strong>Reality → Observation → Model</strong>—has served humanity well. It is the foundation of science, perception, and learning. But as we build artificial systems capable of modeling the world, we are no longer confined to this human-centric path. AI presents an opportunity to explore entirely new ways of perceiving and understanding reality—perhaps ones that bypass the human observer altogether.</p> <p>This possibility is exciting, but also deeply challenging. Humans have spent centuries observing the world and constructing languages to describe it. These languages—mathematical, symbolic, spoken—have shaped our models of reality and, in turn, shaped what we pass on to AI systems. Today’s large language models, for example, don’t observe the world directly. They observe human descriptions of the world—textual artifacts shaped by our cognition, our biases, and our history.</p> <p>For AI to go beyond this, to observe raw reality and construct its own model, perhaps even its own language, would mark a profound shift. Such a system wouldn’t be “thinking like a human,” but rather developing a fundamentally different mode of understanding.</p> <p>Could this help machines reach the state of a Von Neumann universal constructor? Perhaps by learning raw reality we can bridge the gap between the world of bits to the world of atoms for these thinking machines. This move toward embodied intelligence aligns with the trajectory of next-generation AI: systems that don’t just read about reality but live within it, explore it, and interact with it. Language models may help AIs talk about the world. But sensorimotor models will help them exist in it.</p> <p>Yet this raises an important question: Is that what we want? If the purpose of AI is to assist humans, collaborate with us, and serve human goals, it must remain intelligible. Even if an AI could form its own reality-model from first principles, would it be able to communicate that back to us? Would we be able to understand an alien language built from patterns we never noticed or processed?</p> <hr/>]]></content><author><name></name></author><category term="physics"/><category term="physics"/><category term="research"/><category term="philosophy-of-science"/><category term="AI"/><summary type="html"><![CDATA[How humans observe reality and how machines can learn from it]]></summary></entry><entry><title type="html">The Great Stagnation Era of Physics</title><link href="https://alig146.github.io/blog/2025/stagnation-of-physics/" rel="alternate" type="text/html" title="The Great Stagnation Era of Physics"/><published>2025-08-02T10:00:00+00:00</published><updated>2025-08-02T10:00:00+00:00</updated><id>https://alig146.github.io/blog/2025/stagnation-of-physics</id><content type="html" xml:base="https://alig146.github.io/blog/2025/stagnation-of-physics/"><![CDATA[<p>The 20th century saw a series of radical transformations in our understanding of the physical world. The work of Planck, Schrödinger, Einstein, and Feynman, among others, dismantled the classical framework and established the quantum and relativistic paradigms that define modern physics. The technologies that have since reshaped society, from semiconductors to global positioning systems, are direct applications of these foundational theories. A stark contrast has emerged in our own time: while technology advances at an accelerating pace, progress on the most fundamental questions in physics appears to have significantly decelerated.</p> <p>The discovery of the Higgs boson in 2012 was a monumental experimental achievement and a profound validation of the Standard Model. However, it was also a moment of consolidation rather than revolution. It was the capstone of a theoretical structure formulated decades prior, and since its discovery, no comparable, paradigm-shifting results have emerged from experimental particle physics. The Standard Model, despite its known incompleteness, its silence on dark matter, dark energy, and quantum gravity, has remained empirically unchallenged. This raises a critical question: is this plateau a natural feature of the scientific frontier, or is it symptomatic of structural issues within the discipline itself? A contributing factor is undoubtedly the changing sociology of how physics is done. The model of an individual or small group driving foundational change has been largely supplanted, particularly in experimental physics, by massive, international collaborations. Projects like the LHC or next-generation neutrino experiments are essential for probing high-energy scales, but their operational structure, with its immense bureaucratic overhead and consensus-driven decision-making, is inherently conservative. It is a system optimized for complex data analysis and incremental precision, not necessarily for nurturing high-risk, conceptually novel avenues of inquiry.</p> <p>This institutional structure is coupled with intense career pressures. The demand for constant, incremental output for publications and the necessity of securing grants within established research programs leave little room for the kind of prolonged, unstructured investigation that historically led to major breakthroughs. The current academic ecosystem rewards specialization and technical proficiency but may inadvertently penalize the time-intensive, foundational thinking that is not guaranteed to yield near-term, fundable results. Publicly funded projects should be the highest risk projects not the lowest as it seems to be the case now.</p> <p>This trend toward intellectual narrowing is also evident in theoretical physics. For several decades, a significant fraction of the community’s resources and talent was directed toward specific theoretical programs. String theory serves as the primary case study. Its mathematical elegance and ambition to unify quantum mechanics and general relativity were compelling, and its formal development yielded powerful new tools and insights in mathematics and quantum field theory. However, as a physical theory, its decades of development have yet to produce a single falsifiable prediction, and its dominance has arguably fostered a degree of intellectual monoculture. The question is not whether the theory has merit, but why it was allowed to so thoroughly dictate the direction of fundamental theory for so long in the absence of empirical support. It points to a systemic vulnerability: a tendency for institutional prestige, and sociological factors to channel research into directions that may not be the most scientifically productive.</p> <p>A course correction may require more than just new experiments or formalisms; it may require a shift in our research culture. There is a need to reconsider the philosophical and methodological underpinnings of our approach. This is not a call to abandon rigor, but to augment it with a deliberate openness to conceptual diversity. It means blocking cultural filters that may infiltrate the sciences and prohibit broader consideration of thoughts. It means creating and protecting intellectual spaces where foundational assumptions can be critically re-examined without immediate penalty. It involves developing funding mechanisms that explicitly support high-risk, conceptually-driven research that falls outside the mainstream. The thought experiments of Einstein and the persistent epistemological debates of Bohr were not separate from their physics; they were integral to it.</p> <p>The current situation is not one of failure, but of a potential impasse. The confluence of the immense scale of modern experiments, the institutional pressures of academia, and a degree of theoretical conformity has created significant inertia. To move beyond it, we may need to actively cultivate an environment that values conceptual daring as much as technical mastery, and re-integrate the practice of deep, philosophical questioning into the heart of physics.</p> <hr/>]]></content><author><name></name></author><category term="physics"/><category term="physics"/><category term="particle-physics"/><category term="academia"/><category term="research"/><category term="science-policy"/><category term="standard-model"/><category term="philosophy-of-science"/><category term="theoretical-physics"/><summary type="html"><![CDATA[some thoughts on why we may be seeing a derease in major discoveries in particle physics]]></summary></entry></feed>